# Phase 0 Backend — Detailed Implementation Guide

---

## Table of Contents

1. [What's Shared Across Apps](#1-whats-shared-across-apps)
2. [Fastify Setup with Hot Reload](#2-fastify-setup-with-hot-reload)
3. [Upstash Redis Client Setup](#3-upstash-redis-client-setup)
4. [Third-Party Services vs Code Changes](#4-third-party-services-vs-code-changes)

---

## 1. What's Shared Across Apps

The `packages/shared` directory contains code that both the API server and the Next.js web app import. The native mobile apps (iOS/Android) can't use this TypeScript code directly, but they benefit from it indirectly through the generated OpenAPI spec.

### What Goes in Shared (and Why)

```
packages/shared/src/
├── schemas/           # Zod validation schemas
│   ├── user.ts
│   ├── home.ts
│   ├── room.ts
│   ├── item.ts
│   ├── task.ts
│   └── subscription.ts
├── types/             # TypeScript types derived from schemas
│   └── index.ts
├── constants/         # Business logic constants
│   ├── tiers.ts
│   ├── categories.ts
│   ├── recurrence.ts
│   └── errors.ts
└── utils/             # Pure utility functions
    ├── dates.ts
    └── validation.ts
```

### Schemas — The Most Important Shared Code

Zod schemas are the single source of truth for "what shape is this data?" They're used by the API for request validation and by the web app for form validation. One definition, two consumers.

```typescript
// packages/shared/src/schemas/item.ts

import { z } from 'zod';

// ---------- Base schema: fields that exist on every item ----------

// This defines the complete shape of an item as it exists in the database
// and comes back from the API. Both the API and web app import this.
export const itemSchema = z.object({
  id: z.string().uuid(),
  roomId: z.string().uuid(),
  name: z.string().min(1).max(200),
  description: z.string().max(2000).nullable(),
  category: z.string().max(50).nullable(),
  manufacturer: z.string().max(200).nullable(),
  modelNumber: z.string().max(100).nullable(),
  serialNumber: z.string().max(100).nullable(),
  purchaseDate: z.coerce.date().nullable(),
  purchasePrice: z.number().min(0).max(9999999.99).nullable(),
  warrantyUntil: z.coerce.date().nullable(),
  condition: z.enum(['excellent', 'good', 'fair', 'poor']).nullable(),
  metadata: z.record(z.unknown()).default({}),
  createdAt: z.coerce.date(),
  updatedAt: z.coerce.date(),
});

// ---------- Request schemas: what clients send TO the API ----------

// When creating a new item, the client sends these fields.
// The id, createdAt, and updatedAt are generated by the server.
export const createItemSchema = z.object({
  roomId: z.string().uuid(),
  name: z.string().min(1, 'Item name is required').max(200),
  description: z.string().max(2000).optional(),
  category: z.string().max(50).optional(),
  manufacturer: z.string().max(200).optional(),
  modelNumber: z.string().max(100).optional(),
  serialNumber: z.string().max(100).optional(),
  purchaseDate: z.coerce.date().optional(),
  purchasePrice: z.number().min(0).max(9999999.99).optional(),
  warrantyUntil: z.coerce.date().optional(),
  condition: z.enum(['excellent', 'good', 'fair', 'poor']).optional(),
  metadata: z.record(z.unknown()).optional(),
});

// When updating an item, every field is optional (partial update).
// The API only changes the fields that are included in the request.
export const updateItemSchema = createItemSchema.partial();

// ---------- Query schemas: filtering and search parameters ----------

export const itemQuerySchema = z.object({
  roomId: z.string().uuid().optional(),
  category: z.string().optional(),
  search: z.string().max(200).optional(),
  page: z.coerce.number().int().min(1).default(1),
  limit: z.coerce.number().int().min(1).max(100).default(20),
  sortBy: z.enum(['name', 'createdAt', 'purchaseDate', 'category']).default('name'),
  sortOrder: z.enum(['asc', 'desc']).default('asc'),
});

// ---------- Type exports ----------

// These generate TypeScript types from the schemas.
// Instead of defining the type separately (which can drift out of sync),
// the type IS the schema. Change the schema, the type updates automatically.
export type Item = z.infer<typeof itemSchema>;
export type CreateItemInput = z.infer<typeof createItemSchema>;
export type UpdateItemInput = z.infer<typeof updateItemSchema>;
export type ItemQuery = z.infer<typeof itemQuerySchema>;
```

```typescript
// packages/shared/src/schemas/home.ts

import { z } from 'zod';

export const homeSchema = z.object({
  id: z.string().uuid(),
  ownerId: z.string().uuid(),
  name: z.string().min(1).max(200),
  address: z.string().max(500).nullable(),
  homeType: z.enum(['single_family', 'duplex', 'condo', 'townhouse', 'apartment', 'other']).nullable(),
  yearBuilt: z.number().int().min(1600).max(2100).nullable(),
  squareFeet: z.number().int().min(0).nullable(),
  photoUrl: z.string().url().nullable(),
  createdAt: z.coerce.date(),
  updatedAt: z.coerce.date(),
});

export const createHomeSchema = z.object({
  name: z.string().min(1, 'Home name is required').max(200),
  address: z.string().max(500).optional(),
  homeType: z.enum(['single_family', 'duplex', 'condo', 'townhouse', 'apartment', 'other']).optional(),
  yearBuilt: z.number().int().min(1600).max(2100).optional(),
  squareFeet: z.number().int().min(0).optional(),
});

export const updateHomeSchema = createHomeSchema.partial();

export type Home = z.infer<typeof homeSchema>;
export type CreateHomeInput = z.infer<typeof createHomeSchema>;
export type UpdateHomeInput = z.infer<typeof updateHomeSchema>;
```

```typescript
// packages/shared/src/schemas/task.ts

import { z } from 'zod';

export const recurrenceTypeEnum = z.enum([
  'none',
  'daily',
  'weekly',
  'monthly',
  'yearly',
  'custom_days',
]);

export const taskStatusEnum = z.enum([
  'pending',
  'in_progress',
  'completed',
  'skipped',
]);

export const taskSchema = z.object({
  id: z.string().uuid(),
  homeId: z.string().uuid(),
  itemId: z.string().uuid().nullable(),
  createdBy: z.string().uuid(),
  assignedTo: z.string().uuid().nullable(),
  title: z.string().min(1).max(300),
  description: z.string().max(5000).nullable(),
  priority: z.number().int().min(0).max(3).default(0),
  recurrence: recurrenceTypeEnum.default('none'),
  recurrenceInterval: z.number().int().min(1).default(1),
  recurrenceDay: z.number().int().min(0).max(31).nullable(),
  recurrenceEndDate: z.coerce.date().nullable(),
  customDays: z.number().int().min(1).nullable(),
  nextDueDate: z.coerce.date().nullable(),
  notifyDaysBefore: z.number().int().min(0).max(30).default(1),
  notifyDayOf: z.boolean().default(true),
  isActive: z.boolean().default(true),
  createdAt: z.coerce.date(),
  updatedAt: z.coerce.date(),
});

export const createTaskSchema = z.object({
  homeId: z.string().uuid(),
  itemId: z.string().uuid().optional(),
  assignedTo: z.string().uuid().optional(),
  title: z.string().min(1, 'Task title is required').max(300),
  description: z.string().max(5000).optional(),
  priority: z.number().int().min(0).max(3).default(0),
  recurrence: recurrenceTypeEnum.default('none'),
  recurrenceInterval: z.number().int().min(1).default(1),
  recurrenceDay: z.number().int().min(0).max(31).optional(),
  recurrenceEndDate: z.coerce.date().optional(),
  customDays: z.number().int().min(1).optional(),
  nextDueDate: z.coerce.date().optional(),
  notifyDaysBefore: z.number().int().min(0).max(30).default(1),
  notifyDayOf: z.boolean().default(true),
});

export const updateTaskSchema = createTaskSchema.partial();

export type Task = z.infer<typeof taskSchema>;
export type CreateTaskInput = z.infer<typeof createTaskSchema>;
export type UpdateTaskInput = z.infer<typeof updateTaskSchema>;
export type RecurrenceType = z.infer<typeof recurrenceTypeEnum>;
export type TaskStatus = z.infer<typeof taskStatusEnum>;
```

### How the API Uses Shared Schemas

```typescript
// apps/api/src/modules/inventory/inventory.routes.ts

import { createItemSchema, updateItemSchema, itemQuerySchema } from '@homeapp/shared';
import type { CreateItemInput, ItemQuery } from '@homeapp/shared';

// Fastify validates the request body against the Zod schema
// BEFORE your route handler even runs. If validation fails,
// Fastify automatically returns a 400 error with details.
export async function itemRoutes(app: FastifyInstance) {
  app.post('/api/homes/:homeId/rooms/:roomId/items', {
    schema: {
      body: zodToJsonSchema(createItemSchema),
      // This converts the Zod schema to JSON Schema, which is
      // what Fastify's built-in validation expects.
    },
  }, async (req, reply) => {
    // If we get here, req.body is guaranteed to match CreateItemInput.
    // Fastify already rejected any malformed requests.
    const input: CreateItemInput = req.body;
    const item = await inventoryService.createItem(input, req.user.id);
    return reply.status(201).send(item);
  });
}
```

### How the Web App Uses Shared Schemas

```typescript
// apps/web/src/components/ItemForm.tsx

import { createItemSchema } from '@homeapp/shared';
import type { CreateItemInput } from '@homeapp/shared';
import { useForm } from 'react-hook-form';
import { zodResolver } from '@hookform/resolvers/zod';

// The SAME schema that validates on the server also validates
// on the client. If you add a field to the schema, both the
// API and the form require it automatically.
export function ItemForm({ onSubmit }: { onSubmit: (data: CreateItemInput) => void }) {
  const form = useForm<CreateItemInput>({
    resolver: zodResolver(createItemSchema),
    defaultValues: {
      name: '',
      category: undefined,
    },
  });

  return (
    <form onSubmit={form.handleSubmit(onSubmit)}>
      <input {...form.register('name')} />
      {form.formState.errors.name && (
        <span>{form.formState.errors.name.message}</span>
        // Shows "Item name is required" — from the schema definition
      )}
      {/* ... other fields ... */}
    </form>
  );
}
```

### Constants — Shared Business Logic

```typescript
// packages/shared/src/constants/tiers.ts

// These define what each subscription tier gets.
// The API checks these before allowing operations.
// The web app reads these to show limits in the UI.
// Change once, both apps update.
export const TIER_LIMITS = {
  free: {
    maxHomes: 1,
    maxItems: 50,
    maxTasks: 25,
    canShare: false,
    canAttach: false,
    maxFileMb: 5,
  },
  basic: {
    maxHomes: 3,
    maxItems: 500,
    maxTasks: 200,
    canShare: true,
    canAttach: true,
    maxFileMb: 25,
  },
  premium: {
    maxHomes: Infinity,
    maxItems: Infinity,
    maxTasks: Infinity,
    canShare: true,
    canAttach: true,
    maxFileMb: 100,
  },
} as const;

export type TierName = keyof typeof TIER_LIMITS;
```

```typescript
// packages/shared/src/constants/categories.ts

// Item categories and their icons/labels.
// Used by the API for validation and by the web/mobile apps for display.
export const ITEM_CATEGORIES = [
  { value: 'appliance', label: 'Appliance', icon: 'refrigerator' },
  { value: 'furniture', label: 'Furniture', icon: 'couch' },
  { value: 'hvac', label: 'HVAC System', icon: 'thermometer' },
  { value: 'plumbing', label: 'Plumbing', icon: 'droplet' },
  { value: 'electrical', label: 'Electrical', icon: 'zap' },
  { value: 'structural', label: 'Structural', icon: 'home' },
  { value: 'outdoor', label: 'Outdoor/Landscaping', icon: 'tree' },
  { value: 'safety', label: 'Safety/Security', icon: 'shield' },
  { value: 'electronics', label: 'Electronics', icon: 'monitor' },
  { value: 'other', label: 'Other', icon: 'box' },
] as const;

export const CATEGORY_VALUES = ITEM_CATEGORIES.map(c => c.value);
```

```typescript
// packages/shared/src/constants/errors.ts

// Standardized error codes used by the API and understood by all clients.
// The API returns these codes; clients use them to show appropriate messages.
export const ERROR_CODES = {
  // Auth
  UNAUTHORIZED: 'UNAUTHORIZED',
  TOKEN_EXPIRED: 'TOKEN_EXPIRED',

  // Tier limits
  TIER_LIMIT_HOMES: 'TIER_LIMIT_HOMES',
  TIER_LIMIT_ITEMS: 'TIER_LIMIT_ITEMS',
  TIER_LIMIT_TASKS: 'TIER_LIMIT_TASKS',
  TIER_FEATURE_DISABLED: 'TIER_FEATURE_DISABLED',

  // Resources
  NOT_FOUND: 'NOT_FOUND',
  FORBIDDEN: 'FORBIDDEN',
  VALIDATION_ERROR: 'VALIDATION_ERROR',
  CONFLICT: 'CONFLICT',

  // Rate limiting
  RATE_LIMITED: 'RATE_LIMITED',

  // Server
  INTERNAL_ERROR: 'INTERNAL_ERROR',
} as const;

// Standardized error response shape. Every error from the API
// looks like this. All clients can rely on this structure.
export const apiErrorSchema = z.object({
  code: z.string(),
  message: z.string(),
  details: z.unknown().optional(),
});

export type ApiError = z.infer<typeof apiErrorSchema>;
```

### What About iOS and Android?

The native apps can't import TypeScript packages. But they benefit from shared code in two ways:

1. **OpenAPI spec generation.** The Zod schemas are converted to an OpenAPI specification. From that spec, you auto-generate Swift Codable structs and Kotlin data classes that mirror the exact same data shapes. The schemas are the single source of truth; the native code is generated from them.

2. **Constants duplication.** Things like tier limits, categories, and error codes need to be manually duplicated in Swift and Kotlin. This is a tradeoff of going native. Keep these constants in small, clearly labeled files on each platform, and update them as part of any PR that changes the shared package.

### Shared Package Setup

```json
// packages/shared/package.json
{
  "name": "@homeapp/shared",
  "version": "0.1.0",
  "main": "./dist/index.js",
  "types": "./dist/index.d.ts",
  "scripts": {
    "build": "tsup src/index.ts --format cjs,esm --dts",
    "dev": "tsup src/index.ts --format cjs,esm --dts --watch"
  },
  "dependencies": {
    "zod": "^3.23.0"
  },
  "devDependencies": {
    "tsup": "^8.0.0",
    "typescript": "^5.4.0"
  }
}
```

```typescript
// packages/shared/src/index.ts — barrel export

// Schemas
export * from './schemas/user';
export * from './schemas/home';
export * from './schemas/room';
export * from './schemas/item';
export * from './schemas/task';
export * from './schemas/subscription';

// Constants
export * from './constants/tiers';
export * from './constants/categories';
export * from './constants/errors';
export * from './constants/recurrence';

// Utils
export * from './utils/dates';
export * from './utils/validation';
```

The API and web app import from it like any other package:

```typescript
// In apps/api or apps/web:
import { createItemSchema, TIER_LIMITS, ERROR_CODES } from '@homeapp/shared';
```

Turborepo understands that `@homeapp/shared` is a local package and builds it before building the apps that depend on it.

---

## 2. Fastify Setup with Hot Reload

Hot reload means your running server automatically restarts when you save a file. Without it, you'd manually stop the server, run the build, and start it again every time you change a line of code. Over a day of development, that adds up to a shocking amount of wasted time.

### Install Dependencies

```bash
cd apps/api
npm init -y
npm install fastify @fastify/cors @fastify/helmet @fastify/rate-limit
npm install zod zod-to-json-schema
npm install -D typescript tsx @types/node
```

**What each package does:**

- `fastify` — the web framework. Handles HTTP requests and responses.
- `@fastify/cors` — Cross-Origin Resource Sharing. Controls which websites/apps can call your API.
- `@fastify/helmet` — sets security-related HTTP headers automatically (prevents clickjacking, XSS, etc.).
- `@fastify/rate-limit` — limits how many requests a single user can make per time period.
- `zod` — schema validation (shared with the web app).
- `zod-to-json-schema` — converts Zod schemas to JSON Schema format, which Fastify's built-in validation uses.
- `typescript` — the TypeScript compiler.
- `tsx` — runs TypeScript directly without a separate compile step, and includes a file watcher for hot reload. This is the key tool.
- `@types/node` — TypeScript type definitions for Node.js built-in APIs.

### Configure TypeScript

```json
// apps/api/tsconfig.json
{
  "compilerOptions": {
    "target": "ES2022",
    "module": "ESNext",
    "moduleResolution": "bundler",
    "esModuleInterop": true,
    "strict": true,
    "outDir": "dist",
    "rootDir": "src",
    "resolveJsonModule": true,
    "declaration": true,
    "sourceMap": true,
    "skipLibCheck": true,
    "forceConsistentCasingInFileNames": true,
    "paths": {
      "@homeapp/shared": ["../../packages/shared/src"]
    }
  },
  "include": ["src/**/*"],
  "exclude": ["node_modules", "dist"]
}
```

### Package.json Scripts

```json
// apps/api/package.json
{
  "name": "@homeapp/api",
  "version": "0.1.0",
  "type": "module",
  "scripts": {
    "dev": "tsx watch src/server.ts",
    "build": "tsc",
    "start": "node dist/server.js",
    "test": "vitest",
    "lint": "eslint src/"
  }
}
```

**The `dev` script is the hot reload.** Here's what `tsx watch src/server.ts` does:

1. `tsx` compiles your TypeScript to JavaScript in memory (no dist/ folder during development).
2. `watch` tells tsx to monitor all files in your project.
3. When you save any `.ts` file, tsx kills the running server process and starts a fresh one with the new code.
4. The full restart typically takes 200-500 milliseconds — fast enough to feel instant.

### The Server Entry Point

```typescript
// apps/api/src/server.ts

import Fastify from 'fastify';
import cors from '@fastify/cors';
import helmet from '@fastify/helmet';
import rateLimit from '@fastify/rate-limit';
import { env } from './config.js';

// ---------- Create the Fastify instance ----------

const app = Fastify({
  logger: {
    // In development, log in a human-readable format.
    // In production, log as JSON for log aggregation tools.
    transport: env.NODE_ENV === 'development'
      ? { target: 'pino-pretty', options: { colorize: true } }
      : undefined,
    level: env.NODE_ENV === 'development' ? 'debug' : 'info',
  },
});

// ---------- Register global plugins ----------

// Security headers (X-Frame-Options, X-Content-Type-Options, etc.)
await app.register(helmet);

// CORS: allow requests only from your own frontends
await app.register(cors, {
  origin: env.CORS_ORIGINS.split(','),
  credentials: true,
});

// Rate limiting: protect against abuse
await app.register(rateLimit, {
  max: 100,            // 100 requests...
  timeWindow: '1 minute', // ...per minute...
  // per user (identified by JWT) or per IP if not authenticated
  keyGenerator: (req) => {
    return req.user?.id || req.ip;
  },
});

// ---------- Register route modules ----------

// Each module is a Fastify plugin. This keeps routes organized
// and lets each module have its own middleware.
// These are placeholder imports — you'll build these in later phases.
// import { authRoutes } from './modules/auth/auth.routes.js';
// import { inventoryRoutes } from './modules/inventory/inventory.routes.js';
// import { taskRoutes } from './modules/tasks/tasks.routes.js';

// await app.register(authRoutes, { prefix: '/api/auth' });
// await app.register(inventoryRoutes, { prefix: '/api' });
// await app.register(taskRoutes, { prefix: '/api' });

// ---------- Health check endpoint ----------

// This is used by monitoring services and Railway to verify
// the server is running and can reach its dependencies.
app.get('/health', async (req, reply) => {
  // In a real health check, you'd also ping the database and Redis
  // to make sure those connections are alive.
  return { status: 'ok', timestamp: new Date().toISOString() };
});

// ---------- Global error handler ----------

app.setErrorHandler((error, req, reply) => {
  // Log the full error server-side
  req.log.error(error);

  // Never leak internal error details to the client in production.
  // In development, include the full message for easier debugging.
  const statusCode = error.statusCode || 500;
  const response = {
    code: error.code || 'INTERNAL_ERROR',
    message: env.NODE_ENV === 'development'
      ? error.message
      : statusCode >= 500
        ? 'An internal error occurred'
        : error.message,
  };

  reply.status(statusCode).send(response);
});

// ---------- Start the server ----------

const start = async () => {
  try {
    await app.listen({
      port: env.PORT,
      host: '0.0.0.0', // Listen on all interfaces (required for Docker/Railway)
    });
    app.log.info(`Server running on port ${env.PORT}`);
  } catch (err) {
    app.log.fatal(err);
    process.exit(1);
  }
};

start();
```

### The Config Module (Environment Validation)

```typescript
// apps/api/src/config.ts

import { z } from 'zod';
import 'dotenv/config'; // Loads .env file in development

// This schema defines every environment variable your API needs.
// If ANY variable is missing or has the wrong format, the server
// crashes immediately with a clear error message telling you
// exactly what's wrong. This is much better than the alternative:
// the server starts, runs for 3 hours, then crashes when it first
// tries to connect to Redis and finds REDIS_URL is undefined.

const envSchema = z.object({
  NODE_ENV: z.enum(['development', 'staging', 'production']).default('development'),
  PORT: z.coerce.number().default(3000),

  // Database (Neon)
  DATABASE_URL: z.string().min(1, 'DATABASE_URL is required'),
  DATABASE_URL_DIRECT: z.string().min(1, 'DATABASE_URL_DIRECT is required'),

  // Redis (Upstash)
  REDIS_URL: z.string().min(1, 'REDIS_URL is required'),

  // Auth — added in Phase 1, optional for now
  CLERK_SECRET_KEY: z.string().optional(),
  CLERK_PUBLISHABLE_KEY: z.string().optional(),

  // Stripe — added in Phase 6, optional for now
  STRIPE_SECRET_KEY: z.string().optional(),
  STRIPE_WEBHOOK_SECRET: z.string().optional(),

  // File storage — added in Phase 3, optional for now
  R2_ACCOUNT_ID: z.string().optional(),
  R2_ACCESS_KEY_ID: z.string().optional(),
  R2_SECRET_ACCESS_KEY: z.string().optional(),
  R2_BUCKET_NAME: z.string().optional(),

  // Push notifications — added in Phase 7, optional for now
  ONESIGNAL_APP_ID: z.string().optional(),
  ONESIGNAL_API_KEY: z.string().optional(),

  // Application
  JWT_SECRET: z.string().min(32, 'JWT_SECRET must be at least 32 characters'),
  CORS_ORIGINS: z.string().default('http://localhost:3000'),
  API_URL: z.string().url().default('http://localhost:3001'),
});

// Parse and validate. If this throws, the server never starts.
export const env = envSchema.parse(process.env);

// Also export the type so other files can reference it
export type Env = z.infer<typeof envSchema>;
```

### How a Route Module Looks

Each feature area is a Fastify plugin. Here's the pattern you'll follow for every module:

```typescript
// apps/api/src/modules/inventory/inventory.routes.ts

import { FastifyInstance } from 'fastify';
import { inventoryService } from './inventory.service.js';
import { createItemSchema, updateItemSchema, itemQuerySchema } from '@homeapp/shared';
import { zodToJsonSchema } from 'zod-to-json-schema';

// A Fastify plugin is just an async function that receives the app instance.
// Fastify calls this function and passes the app so you can register routes.
export async function inventoryRoutes(app: FastifyInstance) {

  // GET /api/homes/:homeId/items?category=appliance&search=samsung
  app.get('/homes/:homeId/items', {
    schema: {
      querystring: zodToJsonSchema(itemQuerySchema),
    },
  }, async (req, reply) => {
    const { homeId } = req.params as { homeId: string };
    const query = req.query as ItemQuery;
    const items = await inventoryService.getItems(homeId, query, req.user.id);
    return reply.send(items);
  });

  // POST /api/homes/:homeId/rooms/:roomId/items
  app.post('/homes/:homeId/rooms/:roomId/items', {
    schema: {
      body: zodToJsonSchema(createItemSchema),
    },
  }, async (req, reply) => {
    const { homeId, roomId } = req.params as { homeId: string; roomId: string };
    const item = await inventoryService.createItem(
      { ...req.body, roomId },
      req.user.id,
      homeId,
    );
    return reply.status(201).send(item);
  });
}
```

```typescript
// apps/api/src/modules/inventory/inventory.service.ts

import { prisma } from '../../shared/db.js';
import { TIER_LIMITS, ERROR_CODES } from '@homeapp/shared';
import type { CreateItemInput, ItemQuery } from '@homeapp/shared';

// The service layer contains business logic. Routes handle HTTP concerns
// (parsing requests, sending responses). Services handle domain logic
// (checking permissions, enforcing limits, querying the database).
export const inventoryService = {

  async createItem(input: CreateItemInput, userId: string, homeId: string) {
    // 1. Check that the user has access to this home
    const membership = await prisma.homeMember.findFirst({
      where: { homeId, userId, acceptedAt: { not: null } },
    });
    const home = await prisma.home.findFirst({
      where: { id: homeId, ownerId: userId },
    });

    if (!membership && !home) {
      throw new AppError(ERROR_CODES.FORBIDDEN, 'You do not have access to this home', 403);
    }

    // 2. Check tier limits
    const subscription = await prisma.subscription.findUnique({ where: { userId } });
    const tier = subscription?.tier || 'free';
    const limits = TIER_LIMITS[tier];

    const currentCount = await prisma.item.count({
      where: { room: { homeId } },
    });

    if (limits.maxItems !== Infinity && currentCount >= limits.maxItems) {
      throw new AppError(
        ERROR_CODES.TIER_LIMIT_ITEMS,
        `Your ${tier} plan allows ${limits.maxItems} items. Upgrade for more.`,
        403,
      );
    }

    // 3. Create the item
    return prisma.item.create({ data: input });
  },
};
```

### Running in Development

```bash
# Terminal 1: Start the API with hot reload
cd apps/api
npm run dev

# Output:
# [12:00:00] Server running on port 3001
#
# Now edit any .ts file and save. You'll see:
# [12:00:05] Restarting server...
# [12:00:05] Server running on port 3001
```

---

## 3. Upstash Redis Client Setup

### What You Need from Upstash

Upstash is a managed Redis service. Redis is an in-memory data store — it's extremely fast (sub-millisecond responses) because data lives in RAM, not on disk. You're using it for three things in this project:

1. **Caching** — Store frequently-read data (like tier limits for a user) so you don't hit PostgreSQL on every request.
2. **Rate limiting** — Track how many requests each user has made in the current minute.
3. **Pub/Sub** — Broadcast real-time sync events between multiple API server instances (used later for Socket.io).

### Create an Upstash Account and Database

This is the third-party setup part:

1. Go to [console.upstash.com](https://console.upstash.com) and create an account.
2. Click "Create Database."
3. Choose a region close to your Neon database (e.g., US-East-1 if your Neon is in AWS us-east-2).
4. Choose the "Free" plan to start (10,000 commands/day, plenty for development).
5. After creation, you'll see a `UPSTASH_REDIS_REST_URL` and `UPSTASH_REDIS_REST_TOKEN`. Copy both.
6. Also copy the standard `REDIS_URL` (starts with `rediss://`). You need both formats for different clients.

Add to your `.env`:

```bash
# Upstash Redis
REDIS_URL=rediss://default:YOUR_TOKEN@YOUR_ENDPOINT.upstash.io:6379
UPSTASH_REDIS_REST_URL=https://YOUR_ENDPOINT.upstash.io
UPSTASH_REDIS_REST_TOKEN=YOUR_TOKEN
```

### Install Redis Packages

```bash
cd apps/api
npm install @upstash/redis @upstash/ratelimit ioredis
```

**Three packages because they serve different purposes:**

- `@upstash/redis` — Upstash's own HTTP-based Redis client. Works everywhere including serverless environments. Best for caching and simple operations.
- `@upstash/ratelimit` — Pre-built rate limiting library that uses Upstash Redis. Saves you from implementing sliding window rate limiting yourself.
- `ioredis` — Traditional Redis client that uses persistent TCP connections. Needed for Socket.io's Redis adapter (Phase 9) and BullMQ (Phase 5), because those require a persistent connection, not HTTP requests.

### Redis Client Setup

```typescript
// apps/api/src/shared/redis.ts

import { Redis } from '@upstash/redis';
import { Ratelimit } from '@upstash/ratelimit';
import IORedis from 'ioredis';
import { env } from '../config.js';

// ---------- Upstash REST Client ----------
// Used for: caching, simple get/set operations.
// Uses HTTP requests under the hood, so each operation is independent.
// Good for: reading/writing cached data, storing session info.

export const redis = new Redis({
  url: env.UPSTASH_REDIS_REST_URL,
  token: env.UPSTASH_REDIS_REST_TOKEN,
});

// ---------- Rate Limiters ----------
// Pre-configured rate limiting using Upstash's sliding window algorithm.
// A "sliding window" means: "no more than X requests in any rolling
// Y-second period." This is more fair than fixed windows where a user
// could send 100 requests at 11:59:59 and another 100 at 12:00:01.

// Standard API endpoints: 100 requests per 60 seconds
export const standardRateLimit = new Ratelimit({
  redis,
  limiter: Ratelimit.slidingWindow(100, '60 s'),
  analytics: true,    // Track rate limit stats in Upstash dashboard
  prefix: 'rl:standard',
});

// Auth endpoints (login, register): 10 requests per 60 seconds
// Tighter because brute force attacks target these
export const authRateLimit = new Ratelimit({
  redis,
  limiter: Ratelimit.slidingWindow(10, '60 s'),
  prefix: 'rl:auth',
});

// File upload endpoints: 20 requests per 60 seconds
export const uploadRateLimit = new Ratelimit({
  redis,
  limiter: Ratelimit.slidingWindow(20, '60 s'),
  prefix: 'rl:upload',
});

// ---------- IORedis Client ----------
// Used for: Socket.io adapter (Phase 9), BullMQ job queues (Phase 5).
// Maintains a persistent TCP connection to Redis.
// NOT needed in Phase 0 — but set it up now so it's ready.

export const ioRedisClient = new IORedis(env.REDIS_URL, {
  maxRetriesPerRequest: null, // Required by BullMQ
  enableReadyCheck: false,
  // TLS is required for Upstash (the "rediss://" protocol)
  tls: env.REDIS_URL.startsWith('rediss://') ? {} : undefined,
});

ioRedisClient.on('connect', () => {
  console.log('IORedis connected to Upstash');
});

ioRedisClient.on('error', (err) => {
  console.error('IORedis connection error:', err);
});
```

### Using Redis for Caching

```typescript
// apps/api/src/shared/cache.ts

import { redis } from './redis.js';

// A generic caching helper. You give it a cache key, a TTL (time to live),
// and a function that fetches the real data. It returns cached data if
// available, otherwise calls the function, caches the result, and returns it.

export async function cached<T>(
  key: string,
  ttlSeconds: number,
  fetchFn: () => Promise<T>,
): Promise<T> {
  // 1. Try to get from cache
  const cachedValue = await redis.get(key);
  if (cachedValue !== null) {
    // Cache hit — return immediately without touching the database
    return cachedValue as T;
  }

  // 2. Cache miss — fetch the real data
  const freshValue = await fetchFn();

  // 3. Store in cache for next time
  // "EX" means "expire after this many seconds"
  await redis.set(key, JSON.stringify(freshValue), { ex: ttlSeconds });

  return freshValue;
}

// Example usage in a service:
//
// const subscription = await cached(
//   `sub:${userId}`,      // Cache key (unique per user)
//   300,                   // Cache for 5 minutes (300 seconds)
//   () => prisma.subscription.findUnique({ where: { userId } }),
// );
//
// The first call hits PostgreSQL. The next 5 minutes of calls
// return instantly from Redis. After 5 minutes, the cache expires
// and the next call hits PostgreSQL again.
```

### Using Rate Limiting in Middleware

```typescript
// apps/api/src/middleware/rateLimit.ts

import { FastifyRequest, FastifyReply } from 'fastify';
import { standardRateLimit, authRateLimit } from '../shared/redis.js';

// This middleware runs BEFORE your route handler.
// If the user has exceeded their rate limit, it immediately returns
// a 429 (Too Many Requests) error without running any business logic.

export async function rateLimitMiddleware(
  req: FastifyRequest,
  reply: FastifyReply,
) {
  // Use user ID if authenticated, otherwise fall back to IP address
  const identifier = req.user?.id || req.ip;

  const { success, limit, remaining, reset } = await standardRateLimit.limit(
    identifier,
  );

  // Always include rate limit info in response headers.
  // This lets clients know how many requests they have left
  // and when the limit resets.
  reply.header('X-RateLimit-Limit', limit);
  reply.header('X-RateLimit-Remaining', remaining);
  reply.header('X-RateLimit-Reset', reset);

  if (!success) {
    reply.status(429).send({
      code: 'RATE_LIMITED',
      message: 'Too many requests. Please slow down.',
      retryAfter: Math.ceil((reset - Date.now()) / 1000),
    });
    return; // Stop processing — don't run the route handler
  }

  // Rate limit not exceeded — continue to the route handler
}
```

---

## 4. Third-Party Services vs Code Changes

Here's every item in Phase 0, categorized by whether it requires setting up an external account/service or is purely code you write.

### Third-Party Account Setup (Do These First)

These require creating accounts, configuring settings, and getting API keys. Do all of them before writing code so your `.env` file is ready.

| Service | What to Do | What You Get | Cost |
|---------|-----------|-------------|------|
| **Neon** | Create account at neon.tech. Create a project. Create a `development` database. | `DATABASE_URL` (pooled) and `DATABASE_URL_DIRECT` (for migrations). | Free tier: 0.5 GB storage, plenty for development. |
| **Upstash** | Create account at upstash.com. Create a Redis database. | `REDIS_URL`, `UPSTASH_REDIS_REST_URL`, and `UPSTASH_REDIS_REST_TOKEN`. | Free tier: 10,000 commands/day. |
| **GitHub** | Create three repositories: `home-app` (backend + web monorepo), `home-app-ios`, `home-app-android`. Enable branch protection on `main` (require PR reviews). | Git hosting, CI/CD with GitHub Actions. | Free for public or private repos. |
| **Sentry** | Create account at sentry.io. Create a Node.js project. | `SENTRY_DSN` (a URL that tells the Sentry SDK where to send errors). | Free tier: 5,000 errors/month. |
| **Railway** (optional for Phase 0) | Create account at railway.app. You don't need to deploy yet — local development is fine for Phase 0. But creating the account now means you're ready when you want to test deployment. | Deployment platform for later phases. | Free trial, then usage-based. |

**Time estimate for all account setup: 1-2 hours.**

### Code-Only Tasks (No External Services)

Everything below is code you write in your editor. No accounts, no dashboards, no API keys needed.

#### 1. Initialize the Turborepo Monorepo

```bash
# Create the monorepo from scratch
npx create-turbo@latest home-app
cd home-app

# The default Turborepo template gives you a structure like:
# apps/
# packages/
# turbo.json
# package.json

# Remove the template apps and create your own:
rm -rf apps/docs apps/web
mkdir -p apps/api apps/web packages/shared
```

```json
// turbo.json — tells Turborepo how to build your apps
{
  "$schema": "https://turbo.build/schema.json",
  "globalDependencies": ["**/.env.*local"],
  "pipeline": {
    "build": {
      "dependsOn": ["^build"],
      "outputs": ["dist/**"]
    },
    "dev": {
      "cache": false,
      "persistent": true
    },
    "test": {
      "dependsOn": ["build"]
    },
    "lint": {}
  }
}
```

```json
// Root package.json
{
  "name": "home-app",
  "private": true,
  "scripts": {
    "dev": "turbo dev",
    "build": "turbo build",
    "test": "turbo test",
    "lint": "turbo lint"
  },
  "devDependencies": {
    "turbo": "^2.0.0"
  },
  "workspaces": [
    "apps/*",
    "packages/*"
  ]
}
```

Running `npm run dev` from the root starts both the API and web app simultaneously with hot reload.

#### 2. Set Up Prisma with Neon

```bash
cd apps/api
npm install prisma @prisma/client
npx prisma init
```

This creates a `prisma/` directory with a `schema.prisma` file. Configure it to use Neon:

```prisma
// apps/api/prisma/schema.prisma

generator client {
  provider = "prisma-client-js"
}

datasource db {
  provider  = "postgresql"
  url       = env("DATABASE_URL")        // Pooled connection (PgBouncer)
  directUrl = env("DATABASE_URL_DIRECT")  // Direct connection (migrations only)
  // Neon requires directUrl for migrations because PgBouncer doesn't
  // support the transaction mode that migrations need.
}

// ---------- Start with just users and subscriptions ----------
// Add more models in later phases.

model User {
  id            String    @id @default(uuid())
  email         String    @unique
  displayName   String    @map("display_name")
  avatarUrl     String?   @map("avatar_url")
  emailVerified Boolean   @default(false) @map("email_verified")
  isActive      Boolean   @default(true)  @map("is_active")
  createdAt     DateTime  @default(now()) @map("created_at")
  updatedAt     DateTime  @updatedAt      @map("updated_at")
  lastLoginAt   DateTime? @map("last_login_at")
  deletedAt     DateTime? @map("deleted_at")

  subscription  Subscription?
  homes         Home[]

  @@map("users")  // Table name in PostgreSQL
}

model Subscription {
  id                    String             @id @default(uuid())
  userId                String             @unique @map("user_id")
  tier                  SubscriptionTier   @default(free)
  status                SubscriptionStatus @default(active)
  stripeCustomerId      String?            @map("stripe_customer_id")
  stripeSubscriptionId  String?            @map("stripe_subscription_id")
  currentPeriodStart    DateTime?          @map("current_period_start")
  currentPeriodEnd      DateTime?          @map("current_period_end")
  cancelAtPeriodEnd     Boolean            @default(false) @map("cancel_at_period_end")
  createdAt             DateTime           @default(now()) @map("created_at")
  updatedAt             DateTime           @updatedAt      @map("updated_at")

  user                  User               @relation(fields: [userId], references: [id], onDelete: Cascade)

  @@map("subscriptions")
}

model Home {
  id          String   @id @default(uuid())
  ownerId     String   @map("owner_id")
  name        String
  address     String?
  homeType    String?  @map("home_type")
  yearBuilt   Int?     @map("year_built")
  squareFeet  Int?     @map("square_feet")
  photoUrl    String?  @map("photo_url")
  createdAt   DateTime @default(now()) @map("created_at")
  updatedAt   DateTime @updatedAt      @map("updated_at")

  owner       User     @relation(fields: [ownerId], references: [id], onDelete: Cascade)

  @@map("homes")
}

enum SubscriptionTier {
  free
  basic
  premium

  @@map("subscription_tier")
}

enum SubscriptionStatus {
  active
  past_due
  canceled
  trialing

  @@map("subscription_status")
}
```

```bash
# Generate the Prisma client (creates TypeScript types from your schema)
npx prisma generate

# Create the first migration (creates the tables in Neon)
npx prisma migrate dev --name init

# This will:
# 1. Connect to your Neon database using DATABASE_URL_DIRECT
# 2. Generate SQL to create the users, subscriptions, and homes tables
# 3. Save the SQL in prisma/migrations/20260215_init/migration.sql
# 4. Apply the SQL to your database
# 5. Regenerate the Prisma client with updated types
```

Create the Prisma client singleton:

```typescript
// apps/api/src/shared/db.ts

import { PrismaClient } from '@prisma/client';
import { env } from '../config.js';

// Create a single Prisma client instance and reuse it across the app.
// Creating multiple instances would open too many database connections.
export const prisma = new PrismaClient({
  log: env.NODE_ENV === 'development'
    ? ['query', 'warn', 'error']  // Log all queries in development
    : ['warn', 'error'],           // Only warnings and errors in production
});

// Graceful shutdown: close database connections when the server stops
process.on('beforeExit', async () => {
  await prisma.$disconnect();
});
```

#### 3. Set Up Sentry Error Tracking

```bash
cd apps/api
npm install @sentry/node
```

```typescript
// apps/api/src/shared/sentry.ts

import * as Sentry from '@sentry/node';
import { env } from '../config.js';

export function initSentry() {
  if (!env.SENTRY_DSN) {
    console.warn('SENTRY_DSN not set — error tracking disabled');
    return;
  }

  Sentry.init({
    dsn: env.SENTRY_DSN,
    environment: env.NODE_ENV,

    // In production, capture 100% of errors but only 10% of normal
    // transactions (performance monitoring). This keeps costs down.
    tracesSampleRate: env.NODE_ENV === 'production' ? 0.1 : 1.0,
  });
}

// Call this in server.ts before anything else:
// import { initSentry } from './shared/sentry.js';
// initSentry();
```

Update the error handler to report to Sentry:

```typescript
// In server.ts, update the error handler:
import * as Sentry from '@sentry/node';

app.setErrorHandler((error, req, reply) => {
  req.log.error(error);

  // Report 500 errors to Sentry (client errors like 400/404 are expected)
  if (!error.statusCode || error.statusCode >= 500) {
    Sentry.captureException(error, {
      extra: {
        method: req.method,
        url: req.url,
        userId: req.user?.id,
      },
    });
  }

  const statusCode = error.statusCode || 500;
  reply.status(statusCode).send({
    code: error.code || 'INTERNAL_ERROR',
    message: env.NODE_ENV === 'development'
      ? error.message
      : statusCode >= 500
        ? 'An internal error occurred'
        : error.message,
  });
});
```

#### 4. Docker Compose for Local Development

For times when you want to develop without depending on Neon and Upstash (airplane, coffee shop with bad wifi), you can run PostgreSQL and Redis locally:

```yaml
# docker-compose.yml (in the monorepo root)

version: '3.8'
services:
  postgres:
    image: postgres:16
    ports:
      - '5432:5432'
    environment:
      POSTGRES_USER: homeapp
      POSTGRES_PASSWORD: localdev
      POSTGRES_DB: homeapp_dev
    volumes:
      - pgdata:/var/lib/postgresql/data

  redis:
    image: redis:7-alpine
    ports:
      - '6379:6379'

volumes:
  pgdata:
```

```bash
# Start local databases
docker compose up -d

# Use these in your .env for local development:
# DATABASE_URL=postgresql://homeapp:localdev@localhost:5432/homeapp_dev
# DATABASE_URL_DIRECT=postgresql://homeapp:localdev@localhost:5432/homeapp_dev
# REDIS_URL=redis://localhost:6379
```

The Docker Compose setup and the Neon/Upstash cloud setup are interchangeable — your code doesn't care which one it's connected to. Use cloud when you want your database accessible from anywhere, use Docker when you want to work offline.

#### 5. Gitleaks Pre-Commit Hook

```bash
# Install husky (manages Git hooks)
npm install -D husky
npx husky init

# Install gitleaks (you need this on your machine)
# macOS:
brew install gitleaks
# Or download from: https://github.com/gitleaks/gitleaks/releases
```

```bash
# .husky/pre-commit
#!/usr/bin/env sh
gitleaks protect --staged --verbose

# Also run linting
npm run lint
```

Now if you accidentally type an API key into a file and try to commit it, gitleaks blocks the commit and tells you which file contains the secret.

### Phase 0 Complete Checklist

Here's everything in order, with the type of each task:

```
THIRD-PARTY SETUP:
[  ] Create Neon account and database
[  ] Create Upstash account and Redis database
[  ] Create GitHub repositories (backend+web, iOS, Android)
[  ] Create Sentry account and Node.js project
[  ] Gather all API keys/URLs into .env file

CODE (Monorepo foundation):
[  ] Initialize Turborepo monorepo
[  ] Create packages/shared with Zod schemas, types, constants
[  ] Configure turbo.json pipeline

CODE (API server):
[  ] Initialize apps/api with Fastify + TypeScript
[  ] Create config.ts with Zod environment validation
[  ] Create server.ts with Fastify, CORS, Helmet, health check, error handler
[  ] Configure tsx watch for hot reload (package.json dev script)
[  ] Set up Prisma with Neon, create initial schema, run first migration
[  ] Create db.ts Prisma client singleton
[  ] Set up Upstash Redis client (redis.ts) with caching helper and rate limiters
[  ] Set up Sentry error tracking
[  ] Create docker-compose.yml for offline local development
[  ] Create .env.example with all variables documented
[  ] Configure .gitignore
[  ] Install and configure gitleaks pre-commit hook
[  ] Verify: `npm run dev` starts the server with hot reload
[  ] Verify: health check endpoint returns 200
[  ] Verify: Prisma can query the Neon database
[  ] Verify: Redis client can set/get a test value
[  ] Verify: Sentry receives a test error
```
